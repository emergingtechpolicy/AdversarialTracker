# Adversarial Tracker (Work-in-progress)
This repository strives to be a comprehensive list of all publicly-known adversarial attacks, and the state of their corresponding defences (if any). The objective is to allow ML engineers to be able to check this list and mitigate risk of adversarial attacks before deploying machine learning models to the wild.


## Research Papers
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, Pascal Frossard [Universal Adversarial Perturbation](https://arxiv.org/abs/1610.08401)

Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati, Chaowei Xiao, Atul Prakash, Tadayoshi Kohno, Dawn Song [Robust Physical-World Attacks on Deep Learning Models] (https://arxiv.org/abs/1707.08945)

Ian J. Goodfellow, Jonathon Shlens, Christian Szegedy [Explaining and Harnessing Adversarial Examples] (https://arxiv.org/abs/1412.6572)

